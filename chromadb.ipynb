{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a2f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "import numpy as np\n",
    "from typing import List\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n",
    "model = init_chat_model(\"groq:qwen/qwen3-32b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8cfd994",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Retrieval-Augmented Generation (RAG) and Vector Databases\n",
    "    \n",
    "    RAG systems enhance Large Language Models by retrieving relevant data from external sources like ChromaDB or FAISS. \n",
    "    By converting documents into vector embeddings, the system can perform semantic searches to find context \n",
    "    that a model wasn't originally trained on, reducing hallucinations.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Agentic AI and Autonomous Workflows\n",
    "    \n",
    "    Agentic AI refers to systems designed to use tools and make decisions to achieve a goal. \n",
    "    Unlike standard chatbots, AI agents can use 'Reasoning and Acting' (ReAct) patterns to \n",
    "    call APIs, search the web, or execute code independently to complete multi-step tasks.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Cloud-Native Microservices and Scalability\n",
    "    \n",
    "    Modern backend architectures often utilize Spring Boot and Docker to create microservices. \n",
    "    Deploying these on AWS using services like EKS or Lambda allows for elastic scaling. \n",
    "    API Gateways act as the entry point, routing traffic to specific services like Product, Order, or User modules.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Natural Language Processing with NLTK and Transformers\n",
    "    \n",
    "    Natural Language Processing (NLP) involves the interaction between computers and human languages. \n",
    "    Libraries like NLTK are used for basic tokenization and stop-word removal, while Transformer-based \n",
    "    models like BERT or GPT handle complex tasks like sentiment analysis and language translation.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "449315af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\n    Retrieval-Augmented Generation (RAG) and Vector Databases\\n\\n    RAG systems enhance Large Language Models by retrieving relevant data from external sources like ChromaDB or FAISS. \\n    By converting documents into vector embeddings, the system can perform semantic searches to find context \\n    that a model wasn't originally trained on, reducing hallucinations.\\n    \",\n",
       " \"\\n    Agentic AI and Autonomous Workflows\\n\\n    Agentic AI refers to systems designed to use tools and make decisions to achieve a goal. \\n    Unlike standard chatbots, AI agents can use 'Reasoning and Acting' (ReAct) patterns to \\n    call APIs, search the web, or execute code independently to complete multi-step tasks.\\n    \",\n",
       " '\\n    Cloud-Native Microservices and Scalability\\n\\n    Modern backend architectures often utilize Spring Boot and Docker to create microservices. \\n    Deploying these on AWS using services like EKS or Lambda allows for elastic scaling. \\n    API Gateways act as the entry point, routing traffic to specific services like Product, Order, or User modules.\\n    ',\n",
       " '\\n    Natural Language Processing with NLTK and Transformers\\n\\n    Natural Language Processing (NLP) involves the interaction between computers and human languages. \\n    Libraries like NLTK are used for basic tokenization and stop-word removal, while Transformer-based \\n    models like BERT or GPT handle complex tasks like sentiment analysis and language translation.\\n    ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a43ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save sample\n",
    "import tempfile\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "\n",
    "for i , doc in enumerate(sample_docs):\n",
    "    with open(f\"doc.{i}.txt\", \"w\") as f:\n",
    "        f.write(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00fc575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Document Loading\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"Data\",\n",
    "    glob =\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding':'utf-8'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "443e96fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.directory.DirectoryLoader at 0x211c5146d10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45ad5b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c7c3b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Data\\\\doc.0.txt'}, page_content=\"\\n    Retrieval-Augmented Generation (RAG) and Vector Databases\\n\\n    RAG systems enhance Large Language Models by retrieving relevant data from external sources like ChromaDB or FAISS. \\n    By converting documents into vector embeddings, the system can perform semantic searches to find context \\n    that a model wasn't originally trained on, reducing hallucinations.\\n    \"),\n",
       " Document(metadata={'source': 'Data\\\\doc.1.txt'}, page_content=\"\\n    Agentic AI and Autonomous Workflows\\n\\n    Agentic AI refers to systems designed to use tools and make decisions to achieve a goal. \\n    Unlike standard chatbots, AI agents can use 'Reasoning and Acting' (ReAct) patterns to \\n    call APIs, search the web, or execute code independently to complete multi-step tasks.\\n    \"),\n",
       " Document(metadata={'source': 'Data\\\\doc.2.txt'}, page_content='\\n    Cloud-Native Microservices and Scalability\\n\\n    Modern backend architectures often utilize Spring Boot and Docker to create microservices. \\n    Deploying these on AWS using services like EKS or Lambda allows for elastic scaling. \\n    API Gateways act as the entry point, routing traffic to specific services like Product, Order, or User modules.\\n    '),\n",
       " Document(metadata={'source': 'Data\\\\doc.3.txt'}, page_content='\\n    Natural Language Processing with NLTK and Transformers\\n\\n    Natural Language Processing (NLP) involves the interaction between computers and human languages. \\n    Libraries like NLTK are used for basic tokenization and stop-word removal, while Transformer-based \\n    models like BERT or GPT handle complex tasks like sentiment analysis and language translation.\\n    ')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42f1c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Splliting \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0 , length_function = len , separators=[\" \"] )\n",
    "\n",
    "chunk = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d36359e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Data\\\\doc.0.txt'}, page_content='Retrieval-Augmented Generation (RAG) and Vector Databases\\n\\n    RAG systems enhance Large'),\n",
       " Document(metadata={'source': 'Data\\\\doc.0.txt'}, page_content='Language Models by retrieving relevant data from external sources like ChromaDB or FAISS. \\n    By'),\n",
       " Document(metadata={'source': 'Data\\\\doc.0.txt'}, page_content='converting documents into vector embeddings, the system can perform semantic searches to find'),\n",
       " Document(metadata={'source': 'Data\\\\doc.0.txt'}, page_content=\"context \\n    that a model wasn't originally trained on, reducing hallucinations.\"),\n",
       " Document(metadata={'source': 'Data\\\\doc.1.txt'}, page_content='Agentic AI and Autonomous Workflows\\n\\n    Agentic AI refers to systems designed to use tools and'),\n",
       " Document(metadata={'source': 'Data\\\\doc.1.txt'}, page_content=\"make decisions to achieve a goal. \\n    Unlike standard chatbots, AI agents can use 'Reasoning and\"),\n",
       " Document(metadata={'source': 'Data\\\\doc.1.txt'}, page_content=\"Acting' (ReAct) patterns to \\n    call APIs, search the web, or execute code independently to\"),\n",
       " Document(metadata={'source': 'Data\\\\doc.1.txt'}, page_content='complete multi-step tasks.'),\n",
       " Document(metadata={'source': 'Data\\\\doc.2.txt'}, page_content='Cloud-Native Microservices and Scalability\\n\\n    Modern backend architectures often utilize'),\n",
       " Document(metadata={'source': 'Data\\\\doc.2.txt'}, page_content='Spring Boot and Docker to create microservices. \\n    Deploying these on AWS using services like EKS'),\n",
       " Document(metadata={'source': 'Data\\\\doc.2.txt'}, page_content='or Lambda allows for elastic scaling. \\n    API Gateways act as the entry point, routing traffic to'),\n",
       " Document(metadata={'source': 'Data\\\\doc.2.txt'}, page_content='specific services like Product, Order, or User modules.'),\n",
       " Document(metadata={'source': 'Data\\\\doc.3.txt'}, page_content='Natural Language Processing with NLTK and Transformers\\n\\n    Natural Language Processing (NLP)'),\n",
       " Document(metadata={'source': 'Data\\\\doc.3.txt'}, page_content='involves the interaction between computers and human languages. \\n    Libraries like NLTK are used'),\n",
       " Document(metadata={'source': 'Data\\\\doc.3.txt'}, page_content='for basic tokenization and stop-word removal, while Transformer-based \\n    models like BERT or GPT'),\n",
       " Document(metadata={'source': 'Data\\\\doc.3.txt'}, page_content='handle complex tasks like sentiment analysis and language translation.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3fdb2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding Models \n",
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e529003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chroma DB Vector Store \n",
    "persistence_directory = \"./chrom_db\"\n",
    "\n",
    "vectorStore = Chroma.from_documents(\n",
    "    documents=chunk,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=persistence_directory,\n",
    "    collection_name=\"rag_collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a8291e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='fed22f43-38e9-4be4-8e35-d2ec3e2d5f9d', metadata={'source': 'Data\\\\doc.1.txt'}, page_content='Agentic AI and Autonomous Workflows\\n\\n    Agentic AI refers to systems designed to use tools and'),\n",
       " Document(id='b7ed2ebe-41fc-444e-88e4-c2fc37b0dcab', metadata={'source': 'Data\\\\doc.3.txt'}, page_content='Natural Language Processing with NLTK and Transformers\\n\\n    Natural Language Processing (NLP)'),\n",
       " Document(id='0a3feb73-abe5-4cf1-bbb1-bb50110b138f', metadata={'source': 'Data\\\\doc.1.txt'}, page_content=\"make decisions to achieve a goal. \\n    Unlike standard chatbots, AI agents can use 'Reasoning and\")]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text Similarity Search \n",
    "query = \"What refers to Agentic AI?\"\n",
    "\n",
    "similar_docs = vectorStore.similarity_search(query , k=3)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7455193a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='fed22f43-38e9-4be4-8e35-d2ec3e2d5f9d', metadata={'source': 'Data\\\\doc.1.txt'}, page_content='Agentic AI and Autonomous Workflows\\n\\n    Agentic AI refers to systems designed to use tools and'),\n",
       "  0.2739553451538086),\n",
       " (Document(id='b7ed2ebe-41fc-444e-88e4-c2fc37b0dcab', metadata={'source': 'Data\\\\doc.3.txt'}, page_content='Natural Language Processing with NLTK and Transformers\\n\\n    Natural Language Processing (NLP)'),\n",
       "  0.4770853817462921),\n",
       " (Document(id='0a3feb73-abe5-4cf1-bbb1-bb50110b138f', metadata={'source': 'Data\\\\doc.1.txt'}, page_content=\"make decisions to achieve a goal. \\n    Unlike standard chatbots, AI agents can use 'Reasoning and\"),\n",
       "  0.4980132281780243)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Advacne similarity search \n",
    "score = vectorStore.similarity_search_with_score(query , k =3)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81a77ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "376ad732",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model= \"qwen/qwen3-32b\",\n",
    "    temperature= 0.2,\n",
    "    max_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de4ed546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\nOkay, the user is asking what a large language model is. First, I need to define it clearly. A large language model is a type of artificial intelligence that processes and generates human-like text. It's based on deep learning techniques, especially neural networks.\\n\\nNext, I should explain the key components. They are trained on vast amounts of text data, which allows them to understand grammar, context, and even some reasoning. The training process involves predicting the next word in a sentence, which helps them learn patterns and relationships between words.\\n\\nThen, I should mention the different architectures, like the Transformer model, which is widely used. Transformers use attention mechanisms to handle long-range dependencies in text, making them more efficient and effective than older models like RNNs.\\n\\nApplications are important to highlight. They can be used for tasks like translation, summarization, question-answering, and even creative writing. Examples like GPT, BERT, and others can be mentioned to give concrete instances.\\n\\nI should also touch on the training process, including the need for massive datasets and computational resources. This explains why only a few companies can develop such models.\\n\\nPotential challenges and limitations are worth noting too. Issues like data bias, ethical concerns, and the need for continuous updates should be addressed. Also, the difference between understanding and actual knowledge is important—models don't truly understand but simulate based on patterns.\\n\\nFinally, wrap it up by emphasizing their impact on various fields and the ongoing research to improve them. Make sure the explanation is clear and accessible, avoiding too much jargon but still covering the essentials.\\n</think>\\n\\nA **Large Language Model (LLM)** is an advanced type of artificial intelligence (AI) designed to understand, generate, and manipulate human language. These models are trained on vast amounts of text data from the internet, books, articles, and other sources to learn patterns, grammar, context, and relationships between words and phrases. They can perform tasks like answering questions, writing stories, translating languages, summarizing text, and even coding.\\n\\n### Key Characteristics of LLMs:\\n1. **Scale**:  \\n   - LLMs have billions (or even trillions) of parameters, which are the internal variables that the model adjusts during training to improve its predictions. The larger the model, the more complex patterns it can learn.\\n\\n2. **Training Data**:  \\n   - They are trained on massive datasets, often containing diverse text from books, websites, and other sources.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 500, 'prompt_tokens': 13, 'total_tokens': 513, 'completion_time': 1.1007357660000001, 'completion_tokens_details': None, 'prompt_time': 0.000363375, 'prompt_tokens_details': None, 'queue_time': 0.167779614, 'total_time': 1.101099141}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_d58dbe76cd', 'service_tier': 'on_demand', 'finish_reason': 'length', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c4833-fea7-7583-b1ae-a22db7324dda-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 13, 'output_tokens': 500, 'total_tokens': 513})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is Large Language Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ab9fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"groq:qwen/qwen3-32b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86f392f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rag Chain\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatMessagePromptTemplate\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1cd93a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000211C76BFD90>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert vector store ---> Retriever\n",
    "retriever = vectorStore.as_retriever(\n",
    "    search_kwargs={\"k\":3}\n",
    "\n",
    ")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e8ca1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Prompt Template\n",
    "system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer just say don't know.\n",
    "Use three sentence minimum and keep the answer concise.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9b29cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate , MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "758dd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61c2d04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer just say don't know.\\nUse three sentence minimum and keep the answer concise.\\n\\nContext: {context}\\n\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05f79ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain = create_stuff_documents_chain(llm,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47531e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer just say don't know.\\nUse three sentence minimum and keep the answer concise.\\n\\nContext: {context}\\n\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 16384, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x00000211C846A150>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000211C858B890>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39037157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000211C76BFD90>, search_kwargs={'k': 3}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer just say don't know.\\nUse three sentence minimum and keep the answer concise.\\n\\nContext: {context}\\n\\n\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 16384, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x00000211C846A150>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000211C858B890>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain = create_retrieval_chain(retriever , document_chain)\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e19792d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is agentic AI?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea8ad147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user is asking, \"What is agentic AI?\" Let me start by recalling the context provided. The context mentions that agentic AI refers to systems designed to use tools and handle complex tasks like sentiment analysis and language translation. Also, there\\'s a mention of Natural Language Processing with NLTK and Transformers.\\n\\nFirst, I need to define agentic AI clearly. The key points from the context are that it\\'s about systems using tools for complex tasks. But I should expand a bit to make sure the answer is comprehensive. Maybe explain what \"agentic\" means in this context—like autonomy, decision-making, using NLP techniques.\\n\\nWait, the context also connects it to NLP tasks. So, I should mention examples like sentiment analysis and translation. I should link agentic AI to NLP technologies like NLTK and Transformers frameworks, as the context does. That shows how these systems are implemented.\\n\\nThe user might be looking to understand the practical applications or how it\\'s different from regular AI. I should highlight the autonomous workflows and tool usage. Need to keep it concise but cover the main points: definition, tasks handled, and related technologies. Make sure to use three sentences as per the instructions. Let me check if I\\'m missing anything. The answer should be based solely on the provided context, so no external info. Yeah, that should cover it.\\n</think>\\n\\nAgentic AI refers to systems designed to autonomously use tools and execute complex tasks such as sentiment analysis, language translation, and decision-making. These systems often leverage Natural Language Processing (NLP) techniques, including frameworks like NLTK and Transformers, to understand and generate human language. By integrating autonomous workflows, agentic AI aims to perform tasks with minimal human intervention while adapting to dynamic environments.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5853bf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:What does agentic AI refers to ?What is said in cloud native in the document?what is RAG?\n",
      "--------------------------------------------------\n",
      "Answer: <think>\n",
      "Okay, let's break down the user's questions. They asked three things: what agentic AI refers to, what is said about cloud-native in the document, and what RAG is.\n",
      "\n",
      "First, looking at the context provided. The first section is about Agentic AI and Autonomous Workflows. The user's first question is directly about that. The context says Agentic AI refers to systems designed to use tools and... Hmm, the context here seems cut off. But from what's given, I can mention that agentic AI systems use tools and autonomous workflows to perform tasks, possibly with RAG and vector databases.\n",
      "\n",
      "Next, the user is asking about cloud-native in the document. The third section is titled \"Cloud-Native Microservices and Scalability\" and mentions modern backend architectures using cloud-native. The context here is also cut off, but I can infer that cloud-native refers to architectures using microservices and designed for scalability, likely leveraging cloud environments for flexibility and efficiency.\n",
      "\n",
      "Then, the user wants to know what RAG is. The second section mentions Retrieval-Augmented Generation (RAG) and vector databases. RAG systems enhance large models by retrieving relevant information from databases. The context is again incomplete, but RAG typically combines retrieval from a database with generation to improve accuracy and context.\n",
      "\n",
      "I need to answer each part clearly, using the context provided even if it's partial. Make sure each answer is concise, at least three sentences, and if any part is unclear, say \"don't know,\" but the context does provide some info here.\n",
      "</think>\n",
      "\n",
      "Agentic AI refers to systems designed to use tools and autonomous workflows to perform tasks, often leveraging advanced AI techniques like Retrieval-Augmented Generation (RAG) for enhanced decision-making.  \n",
      "\n",
      "The document mentions that cloud-native architectures utilize microservices and prioritize scalability, enabling modern backend systems to efficiently handle dynamic workloads through flexible, distributed designs tailored for cloud environments.  \n",
      "\n",
      "RAG (Retrieval-Augmented Generation) is a method that enhances large language models by integrating external data retrieval from vector databases, improving accuracy and context-awareness in responses by grounding generated outputs in real-world information.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For querying a set of questions\n",
    "def query_rag_modern(question):\n",
    "    print(f\"Question:{question}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    result = rag_chain.invoke({\"input\":question})\n",
    "\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "text_question = [\n",
    "    \"What does agentic AI refers to ?\"\n",
    "    \"What is said in cloud native in the document?\"\n",
    "    \"what is RAG?\"\n",
    "]\n",
    "\n",
    "for question in text_question:\n",
    "    result = query_rag_modern(question)\n",
    "    print(\"\\n\"+ \"=\"*80+ \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8adcda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parser \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough , RunnableParallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79a741d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Use the following context to answer the question. IF you don't know the answer say you don't know.\n",
    "    Provide Specific details from the context to support your answer.\n",
    "    \n",
    "    Context:{context}\n",
    "    Question:{question}\n",
    "    Answer: \n",
    "\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d073667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following context to answer the question. IF you don't know the answer say you don't know.\\n    Provide Specific details from the context to support your answer.\\n\\n    Context:{context}\\n    Question:{question}\\n    Answer: \\n\\n    \"), additional_kwargs={})])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9bd9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the chain using LCEL\n",
    "rag_chain_lcel = (\n",
    "    {\"context\": retriever,\n",
    "     \"question\": RunnablePassthrough()}\n",
    "     |custom_prompt\n",
    "     |llm\n",
    "     |StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9300750e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000211C76BFD90>, search_kwargs={'k': 3}),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"Use the following context to answer the question. IF you don't know the answer say you don't know.\\n    Provide Specific details from the context to support your answer.\\n\\n    Context:{context}\\n    Question:{question}\\n    Answer: \\n\\n    \"), additional_kwargs={})])\n",
       "| ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 16384, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x00000211C846A150>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000211C858B890>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_lcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c27f485b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, let\\'s see. The user is asking about Agentic AI. I need to use the provided context to answer this. Let me check the documents.\\n\\nThe first document has ID \\'fed22f43-38e9-4be4-8e35-d2ec3e2d5f9d\\' and mentions \"Agentic AI refers to systems designed to use tools and\". That seems relevant. The rest of the context includes other documents about NLP, which might not be related. \\n\\nThe user wants a specific answer with details from the context. The first document\\'s page content starts with \"Agentic AI refers to systems designed to use tools and\" but it\\'s cut off. Since there\\'s no more information in the other documents, I have to use that partial sentence. I should mention that the context defines Agentic AI as systems designed to use tools, even though the definition is incomplete. I can\\'t add anything else because the other documents don\\'t talk about Agentic AI. Also, the user said to say \"don\\'t know\" if the answer isn\\'t there, but since there\\'s a partial answer, I should present that and note the incompleteness.\\n</think>\\n\\nAgentic AI refers to systems designed to use tools and (as stated in the context from `doc.1.txt`). However, the provided context is incomplete, as the definition is cut off mid-sentence. No further specific details about Agentic AI are included in the given documents.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_lcel.invoke(\"What is Agentic AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4f401e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding New Documents in the vector Store\n",
    "new_document = \"\"\"\n",
    "Reinforcement Learning in Detail\n",
    "\n",
    "Reinforcement learning (RL) is a type of machine learning where an agent learns to make\n",
    "decisions by interacting with an environment. The agent receives rewards or penalties\n",
    "based on its actions and learns to maximize cumulative reward over time. Key concepts\n",
    "in RL include: states, actions, rewards, policies, and value functions. Popular RL\n",
    "algorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and\n",
    "Actor-Critic methods. RL has been successfully applied to game playing (like AlphaGo),\n",
    "robotics, and autonomous systems.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a223b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = Document(\n",
    "    page_content=new_document,\n",
    "    metadata={\"source\": \"manual_addition\" , \"topic\": \"reinforcement_learning\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4dc9e887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='\\nReinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make\\ndecisions by interacting with an environment. The agent receives rewards or penalties\\nbased on its actions and learns to maximize cumulative reward over time. Key concepts\\nin RL include: states, actions, rewards, policies, and value functions. Popular RL\\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and\\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo),\\nrobotics, and autonomous systems.\\n')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7fdc2c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chunk = text_splitter.split_documents([new_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b3cc289c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='Reinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where'),\n",
       " Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='an agent learns to make\\ndecisions by interacting with an environment. The agent receives rewards or'),\n",
       " Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='penalties\\nbased on its actions and learns to maximize cumulative reward over time. Key concepts\\nin'),\n",
       " Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='RL include: states, actions, rewards, policies, and value functions. Popular RL\\nalgorithms include'),\n",
       " Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and\\nActor-Critic methods. RL has been'),\n",
       " Document(metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='successfully applied to game playing (like AlphaGo),\\nrobotics, and autonomous systems.')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2a0a8692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f0fd363f-7bc7-40e1-9791-a05c3d02d093',\n",
       " '994dcd22-560d-4566-a599-972f3b97ef5f',\n",
       " 'fdf01580-8ec4-47fd-8cd9-b00bc5bb90ee',\n",
       " '52effe70-0d2d-41bd-8d23-5ceb5a97d687',\n",
       " '14193c68-b48b-4def-a70a-7e381868844e',\n",
       " '14447d5c-5782-4185-aaf9-9aeb09512d1c']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorStore.add_documents(new_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cf68f038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:What is reinforcement learning?\n",
      "--------------------------------------------------\n",
      "Answer: <think>\n",
      "Okay, the user is asking, \"What is reinforcement learning?\" I need to answer this using the provided context.\n",
      "\n",
      "Looking at the context, it starts by stating that reinforcement learning (RL) is a type of machine learning. The first sentence is repeated, which might be a formatting error, but the key points are there. Then it mentions some algorithms like Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and Actor-Critic methods. It also says RL has been... but the context cuts off there.\n",
      "\n",
      "So, the answer should define RL as a machine learning type where an agent learns by interacting with an environment to maximize cumulative reward. The main components are the agent, environment, actions, states, and rewards. The mentioned algorithms are examples of RL methods. Since the context doesn't provide more details, I should stick to the given info and not add anything beyond that. Need to make sure the answer is concise, three sentences, and uses the provided terms. Also, avoid any extra information not in the context.\n",
      "</think>\n",
      "\n",
      "Reinforcement learning (RL) is a type of machine learning where an agent learns to make decisions by interacting with an environment to maximize cumulative rewards. It involves learning optimal actions through trial and error, guided by reward signals. Common RL methods include Q-learning, Deep Q-Networks (DQN), Policy Gradient, and Actor-Critic approaches, which enable agents to adapt strategies based on feedback from their actions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is reinforcement learning?',\n",
       " 'context': [Document(id='3d1fbd3d-50ce-44be-8499-9441847dac91', metadata={'topic': 'reinforcement_learning', 'source': 'manual_addition'}, page_content='Reinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where'),\n",
       "  Document(id='f0fd363f-7bc7-40e1-9791-a05c3d02d093', metadata={'source': 'manual_addition', 'topic': 'reinforcement_learning'}, page_content='Reinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where'),\n",
       "  Document(id='14193c68-b48b-4def-a70a-7e381868844e', metadata={'topic': 'reinforcement_learning', 'source': 'manual_addition'}, page_content='Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and\\nActor-Critic methods. RL has been')],\n",
       " 'answer': '<think>\\nOkay, the user is asking, \"What is reinforcement learning?\" I need to answer this using the provided context.\\n\\nLooking at the context, it starts by stating that reinforcement learning (RL) is a type of machine learning. The first sentence is repeated, which might be a formatting error, but the key points are there. Then it mentions some algorithms like Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and Actor-Critic methods. It also says RL has been... but the context cuts off there.\\n\\nSo, the answer should define RL as a machine learning type where an agent learns by interacting with an environment to maximize cumulative reward. The main components are the agent, environment, actions, states, and rewards. The mentioned algorithms are examples of RL methods. Since the context doesn\\'t provide more details, I should stick to the given info and not add anything beyond that. Need to make sure the answer is concise, three sentences, and uses the provided terms. Also, avoid any extra information not in the context.\\n</think>\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make decisions by interacting with an environment to maximize cumulative rewards. It involves learning optimal actions through trial and error, guided by reward signals. Common RL methods include Q-learning, Deep Q-Networks (DQN), Policy Gradient, and Actor-Critic approaches, which enable agents to adapt strategies based on feedback from their actions.'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_question = \"What is reinforcement learning?\"\n",
    "result = query_rag_modern(new_question)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "96331771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversational Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "daf69c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage , AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ad5e3ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a prompt that includes the chat history\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \n",
    "which might reference context in chat history, formulate a standalone question\n",
    "which can be understood without chat history. DO NOT answer the question,\n",
    "just reformulate it if needed and otherwise return it as it is.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "402bad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "300d8ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create history \n",
    "history_aware_retriever = create_history_aware_retriever(llm , retriever ,  contextualize_q_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1badf4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000211C76BFD90>, search_kwargs={'k': 3}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000211A9C94E00>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Given a chat history and the latest user question \\nwhich might reference context in chat history, formulate a standalone question\\nwhich can be understood without chat history. DO NOT answer the question,\\njust reformulate it if needed and otherwise return it as it is.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 16384, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x00000211C846A150>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000211C858B890>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x00000211C76BFD90>, search_kwargs={'k': 3})), kwargs={}, config={'run_name': 'chat_retriever_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c25c96c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new document chain with history\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", qa_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "conversational_rag_chain = create_retrieval_chain(\n",
    "    history_aware_retriever,\n",
    "    question_answer_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bf25375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_hsitory = []\n",
    "\n",
    "result1 = conversational_rag_chain.invoke({\n",
    "    \"chat_history\": chat_hsitory,\n",
    "    \"input\": \"What is reinforcement learning?\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a4428dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking, \"What is reinforcement learning?\" Let me check the context provided.\n",
      "\n",
      "The context starts by stating that reinforcement learning (RL) is a type of machine learning. Then it mentions Q-learning, DQN, Policy Gradient, and Actor-Critic methods as part of RL. It also says RL has been... but the context cuts off there.\n",
      "\n",
      "So, the key points from the context are: RL is a machine learning type where an agent learns by interacting with an environment. The answer should include that it's about learning optimal actions through trial and error, using rewards and penalties. The examples like Q-learning and DQN are important to mention as methods within RL.\n",
      "\n",
      "Wait, the user wants a concise answer in three sentences max. Let me structure that. First sentence defines RL. Second explains how it works (agent, environment, rewards). Third lists some methods. Need to make sure not to include any extra info beyond what's in the context. Also, avoid any markdown and keep it natural.\n",
      "</think>\n",
      "\n",
      "Reinforcement learning (RL) is a type of machine learning where an agent learns to make decisions by interacting with an environment to maximize cumulative rewards. It relies on trial-and-error interactions, guided by feedback in the form of rewards or penalties for specific actions. Common methods include Q-learning, Deep Q-Networks (DQN), and Policy Gradient techniques.\n"
     ]
    }
   ],
   "source": [
    "print(result1['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b159ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_hsitory.extend([\n",
    "    HumanMessage(content=\"What is reinforcement learning?\"),\n",
    "    AIMessage(content=result1['answer'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1f82f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = conversational_rag_chain.invoke({\n",
    "    \"chat_history\" : chat_hsitory,\n",
    "    \"input\": \"What are its types?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e8013813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user is asking about the types of reinforcement learning. Let me check the previous conversation. In the first question, they asked what reinforcement learning is, and I mentioned Q-learning, DQN, Policy Gradient methods, and Actor-Critic methods.\\n\\nNow, the user is following up with \"What are its types?\" So they want more details on the different types. The context provided includes Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and Actor-Critic methods. \\n\\nI need to list these types clearly. But wait, are there more types beyond what\\'s in the context? The context is limited, so I should stick to what\\'s provided. The user might not need an exhaustive list but the main ones mentioned. \\n\\nAlso, the user might be looking for a brief explanation of each type. However, the context doesn\\'t provide detailed explanations, just the names. Since the instruction says to use the retrieved context and not make up information, I should list the types mentioned without adding extra details. \\n\\nSo the answer should include Q-learning, DQN, Policy Gradient, and Actor-Critic methods. Keep it concise, three sentences max. Let me structure that.\\n</think>\\n\\nReinforcement learning includes types such as Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and Actor-Critic methods. These approaches differ in how they balance exploration and exploitation or model policy and value functions. For example, DQN uses deep neural networks for Q-value estimation, while Policy Gradient directly optimizes policies.'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8cbda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_Updated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
