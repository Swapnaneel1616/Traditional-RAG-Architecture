{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a2f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "import numpy as np\n",
    "from typing import List\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n",
    "model = init_chat_model(\"groq:qwen/qwen3-32b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8cfd994",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Retrieval-Augmented Generation (RAG) and Vector Databases\n",
    "    \n",
    "    RAG systems enhance Large Language Models by retrieving relevant data from external sources like ChromaDB or FAISS. \n",
    "    By converting documents into vector embeddings, the system can perform semantic searches to find context \n",
    "    that a model wasn't originally trained on, reducing hallucinations.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Agentic AI and Autonomous Workflows\n",
    "    \n",
    "    Agentic AI refers to systems designed to use tools and make decisions to achieve a goal. \n",
    "    Unlike standard chatbots, AI agents can use 'Reasoning and Acting' (ReAct) patterns to \n",
    "    call APIs, search the web, or execute code independently to complete multi-step tasks.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Cloud-Native Microservices and Scalability\n",
    "    \n",
    "    Modern backend architectures often utilize Spring Boot and Docker to create microservices. \n",
    "    Deploying these on AWS using services like EKS or Lambda allows for elastic scaling. \n",
    "    API Gateways act as the entry point, routing traffic to specific services like Product, Order, or User modules.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Natural Language Processing with NLTK and Transformers\n",
    "    \n",
    "    Natural Language Processing (NLP) involves the interaction between computers and human languages. \n",
    "    Libraries like NLTK are used for basic tokenization and stop-word removal, while Transformer-based \n",
    "    models like BERT or GPT handle complex tasks like sentiment analysis and language translation.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "449315af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\n    Retrieval-Augmented Generation (RAG) and Vector Databases\\n\\n    RAG systems enhance Large Language Models by retrieving relevant data from external sources like ChromaDB or FAISS. \\n    By converting documents into vector embeddings, the system can perform semantic searches to find context \\n    that a model wasn't originally trained on, reducing hallucinations.\\n    \",\n",
       " \"\\n    Agentic AI and Autonomous Workflows\\n\\n    Agentic AI refers to systems designed to use tools and make decisions to achieve a goal. \\n    Unlike standard chatbots, AI agents can use 'Reasoning and Acting' (ReAct) patterns to \\n    call APIs, search the web, or execute code independently to complete multi-step tasks.\\n    \",\n",
       " '\\n    Cloud-Native Microservices and Scalability\\n\\n    Modern backend architectures often utilize Spring Boot and Docker to create microservices. \\n    Deploying these on AWS using services like EKS or Lambda allows for elastic scaling. \\n    API Gateways act as the entry point, routing traffic to specific services like Product, Order, or User modules.\\n    ',\n",
       " '\\n    Natural Language Processing with NLTK and Transformers\\n\\n    Natural Language Processing (NLP) involves the interaction between computers and human languages. \\n    Libraries like NLTK are used for basic tokenization and stop-word removal, while Transformer-based \\n    models like BERT or GPT handle complex tasks like sentiment analysis and language translation.\\n    ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a43ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save sample\n",
    "import tempfile\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "\n",
    "for i , doc in enumerate(sample_docs):\n",
    "    with open(f\"doc.{i}.txt\", \"w\") as f:\n",
    "        f.write(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Document Loading\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"Data\",\n",
    "    glob =\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding':'utf-8'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "443e96fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.directory.DirectoryLoader at 0x211c699dfd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45ad5b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c7c3b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f1c679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_Updated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
